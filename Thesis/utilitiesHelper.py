# utilsNeeded.py
import hashlib
import os
import uuid

import cv2
import csv
import logging

import winsound

from ultralytics import YOLO
import time


# This is helper file used for my both algorithms, functions needed in both
# Authorship Information
"""
Author: Koray Aman Arabzadeh
Thesis: Mid Sweden University.
Bachelor Thesis - Bachelor of Science in Engineering, Specialisation in Computer Engineering
Main field of study: Computer Engineering
Credits: 15 hp (ECTS)
Semester, Year: Spring, 2024
Supervisor: Emin Zerman
Examiner: Stefan ForsstrÃ¶m
Course code: DT099G
Programme: Degree of Bachelor of Science with a major in Computer Engineering



Resources used: 
https://opencv.org/
https://stackoverflow.com/
https://github.com
https://pieriantraining.com/kalman-filter-opencv-python-example/
"""


def get_color_by_id(class_id):
    """
    Generate a unique color for a given class ID.

    This function creates a consistent and unique RGB color for a given input based on its class ID. The color is generated by hashing the class ID to ensure the same ID always returns the same color. This can be useful for color-coding objects in visualization tasks where each object type (class) is represented by a unique color.

    Parameters:
    - class_id (int or str): The class identifier for which the color needs to be generated.

    Returns:
    - list: A list containing the RGB color values as integers.

    Example:
    >>> get_color_by_id(1)
    [150, 200, 75]  # This is an example output and will differ based on input
    """
    hash_value = hashlib.sha256(str(class_id).encode()).hexdigest()
    r = int(hash_value[:2], 16)
    g = int(hash_value[2:4], 16)
    b = int(hash_value[4:6], 16)
    return [r, g, b]


# Function to play a beep sound as an alert

def trigger_proximity_alert(duration=2000, freq=1000):
    """
    Triggers an audible beep alert with a specified frequency and duration.

    This function uses the system's standard audio output to generate a beep sound, which can be used to signal proximity alerts. It's particularly useful in scenarios where immediate user attention is required, such as when an object gets too close to a robotic arm in the tracking system.

    Parameters:
    - duration (int): The duration of the beep in milliseconds. Default is 2000ms (2 seconds).
    - freq (int): The frequency of the beep in hertz. Default is 1000Hz.

    Returns:
    - None

    Example:
    >>> trigger_proximity_alert(1000, 1500)  # Triggers a beep that lasts 1 second with a frequency of 1500Hz.
    """
    winsound.Beep(freq, duration)  # Beep sound for alert


def is_object_within_bounds(det, center_area):
    """
    Determines if an object is within a specified bounding area.

    Parameters:
    - det: Detection details, expected to include the bounding box coordinates (x1, y1, x2, y2).
    - center_area: A tuple containing the coordinates for the top left and bottom right points of the center area (top_left, bottom_right).

    Returns:
    - bool: True if the object is within the center area, False otherwise.
    """
    (x1_obj, y1_obj, x2_obj, y2_obj, _, _, _) = det
    # let x1_obj = 6, x2, = 10, y1 = 12, y2 = 8

    (top_left, bottom_right) = center_area
    #let top_left = (7,12) bottem right =(11,7)
    x1_area, y1_area = top_left
    x2_area, y2_area = bottom_right

    return not (x2_obj < x1_area or x1_obj > x2_area or y2_obj < y1_area or y1_obj > y2_area) # Correct 


def is_object_near_boundary(det, proximity_threshold, center_area):
    """
    Determines if an object is near the boundary of a specified area, within a given proximity threshold,
     is calculated based on the  size of the frame 480x640 iz the totaal size and threshold is the unit of the frame.

    Parameters:
    - det: Detection details, expected to include the bounding box coordinates (x1, y1, x2, y2).
    - proximity_threshold: The distance threshold that defines "nearness".
    - center_area: A tuple containing the coordinates for the top left and bottom right points of the center area (top_left, bottom_right).

    Returns:
    - bool: True if the object is near the boundary of the center area within the specified threshold, False otherwise.
    """
    (x1_obj, y1_obj, x2_obj, y2_obj, _, _, _) = det
    (top_left, bottom_right) = center_area
    x1_area, y1_area = top_left
    x2_area, y2_area = bottom_right

    # Check if the object is near the horizontal or vertical boundaries of the center area within the given threshold
    return ((x1_obj > x2_area and (x1_obj - x2_area) <= proximity_threshold) or
            (x2_obj < x1_area and (x1_area - x2_obj) <= proximity_threshold) or
            (y1_obj > y2_area and (y1_obj - y2_area) <= proximity_threshold) or
            (y2_obj < y1_area and (y1_area - y2_obj) <= proximity_threshold))


import cv2

def draw_predictions(frame, det, current_x, current_y, future_x, future_y, color):
    """
    Draws detection results and predictions on an image (frame).Used to clarify and distingfuash between what is current,
     and what is the predicted values.

    This function visualizes the object detection and movement prediction results by drawing bounding boxes, labels,
    and circles that represent the current and predicted positions of objects on a frame.

    Parameters:
    - frame (np.array): The image frame on which to draw the detection and prediction visualizations.
    - det (list): Detection data for the object, which includes bounding box coordinates and class information.
                  Expected format: [x1, y1, x2, y2, _, class_id, class_name].
    - current_x (int): The current x-coordinate of the object's center.
    - current_y (int): The current y-coordinate of the object's center.
    - future_x (int): The predicted x-coordinate of the object's center in the future.
    - future_y (int): The predicted y-coordinate of the object's center in the future.
    - color (tuple): RGB color tuple to use for drawing the current position and bounding box.

    Returns:
    - None

    Example:
    >>> frame = cv2.imread('example.jpg')
    >>> det = [100, 150, 200, 250, 0.9, 1, 'Object']
    >>> draw_predictions(frame, det, 150, 200, 180, 230, (255, 0, 0))
    """
    x1, y1, x2, y2, _, cls, class_name = det
    cv2.circle(frame, (int(current_x), int(current_y)), 10, color, -1)  # Draw circle at current position
    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)  # Draw bounding box
    label = f"{class_name} ({cls})"  # Label format
    cv2.putText(frame, label, (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)  # Draw label
    cv2.circle(frame, (int(future_x), int(future_y)), 10, (0, 255, 0), -1)  # Draw circle at predicted position










def setup_csv_writer(filename='tracking_and_predictions.csv'):
    """
    Initializes and sets up a CSV writer for logging detection and prediction data.

    This function creates a CSV file and prepares it to log various data points including timestamps,
    detection coordinates, prediction coordinates, and class names. It is particularly useful for
    tracking and analyzing the output of object detection and prediction systems over time.

    Parameters:
    - filename (str): The name of the CSV file to create and write to. Default is 'tracking_and_predictions.csv'.

    Returns:
    - tuple: A tuple containing the file object and the CSV writer object. Returns (None, None) if an error occurs.

    Raises:
    - IOError: If the file cannot be opened or written to.

    Example:
    >>> file, writer = setup_csv_writer('output_data.csv')
    >>> if file is not None and writer is not None:
        writer.writerow(['2021-01-01 00:00:00', 100, 150, 110, 160, 'ObjectA'])
    """
    try:
        file = open(filename, 'w', newline='')  # Open the file for writing, disable newline handling by Python
        writer = csv.writer(file)  # Create a CSV writer object
        writer.writerow(['timestamp', 'det_x', 'det_y', 'pred_x', 'pred_y', 'class_name'])  # Write the header row
        return file, writer
    except IOError as e:
        logging.error(f"File operations failed: {str(e)}")
        return None, None  # Return None, None if an error occurs


def highlight_center_area(frame, center_area, label="Robotic Arm", overlay=None):
    """
    Draws a rectangle on the frame around the specified center area, adds a label at the top center of the rectangle,
    and optionally overlays an image within the rectangle. If an overlay is provided, it is resized to fit the rectangle
    and blended into the frame with partial transparency.

    Parameters:
    - frame (np.array): The image (frame) on which to draw.
    - center_area (tuple): Tuple of (top_left, bottom_right) coordinates for the rectangle.
    - label (str): Text to display inside the rectangle.
    - overlay (np.array, optional): Image to overlay within the rectangle. It will be resized to fit the rectangle if provided.

    Returns:
    - np.array: The modified frame with the rectangle, label, and optional overlay.
    """
    top_left, bottom_right = center_area
    cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)  # Draw the rectangle

    # Calculate label position to be at the top-center of the rectangle
    label_x = (top_left[0] + bottom_right[0]) // 2
    label_y = max(top_left[1] - 10, 10)  # Ensure label is within the frame's boundary

    # Place the label on the frame
    cv2.putText(frame, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)

    # If an overlay image is provided, adjust its size and blend it into the rectangle
    if overlay is not None:
        overlay_height = bottom_right[1] - top_left[1] # if (6,12)  =  4
        overlay_width = bottom_right[0] - top_left[0] #if (10,8) = 4
        resized_overlay = cv2.resize(overlay, (overlay_width, overlay_height))
        # Blend the resized overlay into the rectangle with 50% transparency
        region_of_interest = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]
        frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]] = cv2.addWeighted(
            region_of_interest, 0.5, resized_overlay, 0.5, 0)

    return frame




def update_center_area(frame_width, frame_height, factor=4):
    """
    Calculates the central area of a frame based on its dimensions and a dividing factor.

    This function computes the coordinates of a rectangle that represents the center area of a given frame.
    The size of this central area is determined by the provided factor, which divides the frame dimensions
    to derive the area's width and height.

    Parameters:
    - frame_width (int): The width of the frame (image).
    - frame_height (int): The height of the frame (image).
    - factor (int): The division factor to determine the size of the center area. Default is 4.

    Returns:
    - tuple: A tuple containing the top-left and bottom-right coordinates of the center area rectangle.

    Example:
    >>> update_center_area(800, 600)
    ((300, 200), (500, 400))
    """
    center_x, center_y = frame_width // 2, frame_height // 2  # Calculate center of the frame
    area_width, area_height = frame_width // factor, frame_height // factor  # Determine the dimensions of the center area
    top_left = (center_x - area_width // 2, center_y - area_height // 2)  # Calculate top-left corner
    bottom_right = (center_x + area_width // 2, center_y + area_height // 2)  # Calculate bottom-right corner
    return (top_left, bottom_right)  # Return the coordinates

def log_detection(writer, timestamp, center_x, center_y, future_x, future_y, object_class):
    """
    Logs detection details into a CSV file using a CSV writer.

    Parameters:
    - writer (csv.writer): The CSV writer object used to write to the file.
    - timestamp (float): The timestamp at which the detection was recorded.
    - center_x (int): The current x-coordinate of the detected object.
    - center_y (int): The current y-coordinate of the detected object.
    - future_x (int): The predicted future x-coordinate of the detected object.
    - future_y (int): The predicted future y-coordinate of the detected object.
    - object_class (str): The classification of the detected object.

    Returns:
    - None
    """
    writer.writerow([timestamp, center_x, center_y, future_x, future_y, object_class])

def is_object_near(det, center_area, proximity_threshold):
    """
    Determines if a detected object is near a specific area within a given proximity threshold.

    Parameters:
    - det (list): Detection data including the object's bounding box coordinates.
    - center_area (tuple): A tuple containing the top-left and bottom-right coordinates defining the center area.
    - proximity_threshold (int): The distance threshold that defines "nearness".

    Returns:
    - bool: True if the object is near the defined area, False otherwise.
    """
    return is_object_within_bounds(det, center_area) or is_object_near_boundary(det, proximity_threshold, center_area)


def handle_alert(alert_file, save_alert_times, det, pre_alert_time, post_alert_time, center_x, center_y, future_x, future_y, start_time, center_area):
    hazard_time = post_alert_time - start_time
    alert_condition = "center" if is_object_within_bounds(det, center_area) else "Nearness"
    save_alert_times(alert_file, pre_alert_time, post_alert_time, det[6], center_x, center_y, future_x, future_y, hazard_time, alert_condition, center_area)

def save_alert_times(alert_file, pre_alert_time, post_alert_time, object_class, location_x, location_y, future_pos_x, future_pos_y, hazard_time, alert_condition, center_area):
    alert_duration = post_alert_time - pre_alert_time  # Calculate the duration of the alert
    try:
        needs_header = not os.path.exists(alert_file) or os.stat(alert_file).st_size == 0
        with open(alert_file, 'a', newline='') as file:
            writer = csv.writer(file)
            if needs_header:
                writer.writerow([
                    'Pre-alert DateTime UTC',
                    'Post-alert DateTime UTC',
                    'Alert Duration (seconds)',
                    'Detected Object Type',
                    'Object Location X (px)',
                    'Object Location Y (px)',
                    'Predicted Future Location X (px)',
                    'Predicted Future Location Y (px)',
                    'Hazard Time Since Start (seconds)',
                    'Alert Type',
                    'Center Area Top-Left X (px)',
                    'Center Area Top-Left Y (px)',
                    'Center Area Bottom-Right X (px)',
                    'Center Area Bottom-Right Y (px)'
                ])
            writer.writerow([
                pre_alert_time, post_alert_time, alert_duration, object_class, location_x, location_y, future_pos_x, future_pos_y, hazard_time, alert_condition,
                center_area[0][0], center_area[0][1], center_area[1][0], center_area[1][1]
            ])
    except IOError as e:
        logging.error(f"Failed to save alert time: {str(e)}")



# Default functions needed


def cleanup(cap, file):
    """
    Releases video capture object and closes all OpenCV windows and any open file.

    Parameters:
    - cap (cv2.VideoCapture): The video capture object to release.
    - file (file object): The file object to close, typically a CSV or log file.

    Returns:
    - None
    """
    if cap:
        cap.release()  # Release the video capture object
    cv2.destroyAllWindows()  # Close all OpenCV windows
    if file:
        file.close()  # Close the CSV file if it's open

def load_model(model_path):
    """
    Loads a YOLO model from a specified path.

    Attempts to load a pre-trained YOLO model specified by the path. Logs success or failure.

    Parameters:
    - model_path (str): The file path to the YOLO model.

    Returns:
    - YOLO: Returns an instance of the YOLO model if successful, None otherwise.

    Raises:
    - Exception: If the model fails to load, logs the exception.
    """
    try:
        model = YOLO(model_path)  # Attempt to load the model
        logging.info("Model loaded successfully.")
        return model
    except Exception as e:
        logging.error(f"Failed to load model: {str(e)}")
        return None

def initialize_video_capture(source):
    """
    Initializes and returns a video capture object.

    Attempts to open a video source. If the source can be opened, it returns a VideoCapture object, otherwise, it logs an error and returns None.

    Parameters:
    - source (int or str): The device index or the video file path.

    Returns:
    - cv2.VideoCapture: The initialized video capture object, or None if the operation fails.
    """
    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        logging.error("Failed to open video source.")
        return None
    return cap




def run_yolov8_inference(model, frame):
    """
    Perform object detection on a single image using a preloaded YOLOv8 model.

    Parameters:
    - model: An instance of a YOLOv8 model ready for inference.
    - frame: An image in BGR format (numpy array) for object detection.

    Returns:
    A list of detections, each represented as a list containing:
    [bounding box coordinates (x1, y1, x2, y2), confidence score, class ID, class name]
    """
    # Perform inference with the YOLOv8 model
    results = model.predict(frame)
    detections = []

    # Assuming the first item in results contains the detection information
    if results:
        detection_result = results[0]
        xyxy = detection_result.boxes.xyxy.numpy()  # Bounding box coordinates
        confidence = detection_result.boxes.conf.numpy()  # Confidence scores
        class_ids = detection_result.boxes.cls.numpy().astype(int)  # Class IDs
        class_names = [model.model.names[cls_id] for cls_id in class_ids]  # Class names

        for i in range(len(xyxy)):
            x1, y1, x2, y2 = map(int, xyxy[i])
            conf = confidence[i]
            cls_id = class_ids[i]
            class_name = class_names[i]
            detections.append([x1, y1, x2, y2, conf, cls_id, class_name])

    return detections
